---
title: "EDS 213 Data Cleaning Assignment"
subtitle: "Columns 'Water_cover' and 'Land_cover'"
date: 2025-04-16
format: html
theme: cyborg
author: Kaiju Morquecho
---

Let's load any necessary libraries and write file names

```{r}
library(tidyverse)

# file names 
datadir_processed <- "data/processed/"
datadir_raw <- "data/raw/"
snowsurvey_file <- "ASDN_Snow_survey.csv"
```

Read in the Snow Survey data

```{r message=FALSE}
snowsurvey <- read_csv(file.path(datadir_raw, snowsurvey_file))
```

Use in-class code to clean the Snow_cover column

```{r}
snowsurvey_fixed <- snowsurvey %>%
  mutate(
    Snow_cover = case_when(
      Snow_cover == "." ~ NA, 
      Snow_cover == "-" ~ NA, 
      Snow_cover == "n/a" ~ NA,
      Snow_cover == "unk" ~ NA,
      Snow_cover == "<1" ~ "0", 
      .default = Snow_cover 
    ),
    Snow_cover = as.numeric(Snow_cover)
  )

# check for values > 100 
snowsurvey_fixed %>% 
  filter(Snow_cover > 100) 

# and replace with NA

snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Snow_cover = ifelse(Snow_cover > 100, NA, Snow_cover))

# check for negative values:

snowsurvey_fixed %>% 
  filter(Snow_cover < 0) 

# none, we can leave as is
```

Take a look at snowsurvey_fixed's Snow_cover data type to make sure it looks good now(is numeric)

```{r}
glimpse(snowsurvey_fixed) # we see that Snow_cover is <dbl> but Land and Water are still <chr>
```

Take a look at the Water_cover and Land_cover columns to identify problematic values

```{r}
# if we take a look at the unique values in snowsurvey_fixed we can see what values we must replace/clean before turning into numeric

unique(snowsurvey_fixed$Water_cover) 
unique(snowsurvey_fixed$Land_cover)
```

Replace the identified problematic values in Water_cover ('-','n/a','unk','.')

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(Water_cover = case_when(
    Water_cover %in% c(".","unk","-","n/a") ~ NA,
    .default = Water_cover)
  )
```

Let's check if our replacement worked correctly

```{r}
snowsurvey_fixed %>% 
  count(Water_cover) %>%
  filter(is.na(as.numeric(Water_cover)))
```

It worked, now we only have numbers and NAs. Let's make the transformation

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(Water_cover = as.numeric(Water_cover))
```

Let's check for values greater than 100 or less than 0. The metadata (and logic) suggests checking percentage =< 100.

```{r}
snowsurvey_fixed %>% 
  filter(Water_cover > 100) # more than 100?

snowsurvey_fixed %>% 
  filter(Water_cover < 0) # negative number? less than 0? 

```

We have one value in Water_cover that is > 100 (it's 353). No negative numbers! Let's make those > 100 = NA and check once more

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover > 100, NA, Water_cover))

# recheck
snowsurvey_fixed %>% 
  filter(Water_cover > 100) # more than 100?

# all good
```


## Now let's repeat the steps for Land_cover

Replace the identified problematic values in Land_cover ('-','n/a','unk','.')

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(Land_cover = case_when(
    Land_cover %in% c(".","unk","-","n/a") ~ NA,
    .default = Land_cover)
  )
```

Let's check if our replacement worked correctly

```{r}
snowsurvey_fixed %>% 
  count(Land_cover) %>%
  filter(is.na(as.numeric(Land_cover)))
```

It worked, now we only have numbers and NAs. Let's make the transformation

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(Land_cover = as.numeric(Land_cover))
```

I did not see any values greater than 100 or less than 0. The metadata (and logic) suggests checking percentage =\< 100.

```{r}
snowsurvey_fixed %>% 
  filter(Land_cover > 100) # more than 100?

snowsurvey_fixed %>% 
  filter(Land_cover < 0) # negative number? less than 0? 

```

We have two values in Land_cover that are < 0 (-100 and -298). We have no >100 values. Let's make the negative values = NA

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover < 0, NA, Land_cover))
```

Let's take one final look at Land_cover and Water_cover's data type

```{r}
glimpse(snowsurvey_fixed)
```

Yay. Now all 3 x_cover columns are numeric

### Now that we have numeric columns, let's recompute and infer values for Total_cover

```{r}
# we will check each column for missing values  
snowsurvey_fixed %>%
  filter(is.na(Snow_cover)) %>%
  count() # 798 missing 

snowsurvey_fixed %>%
  filter(is.na(Water_cover)) %>%
  count() # 768 missing 

snowsurvey_fixed %>%
  filter(is.na(Land_cover)) %>%
  count() # 774 missing 

snowsurvey_fixed %>%
  filter(is.na(Total_cover)) %>%
  count() # 81 missing 
```

Since Snow_cover + Land_cover + Water_cover = Total_cover, we will use the columns to infer missing values. First, let's make sure Total_cover is numeric/doesn't have any problematic values.

```{r}
unique(snowsurvey_fixed$Total_cover)
```

We have to clean it up. Let's replace invalid entries with NAs.

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(Total_cover = case_when(
    Total_cover %in% c(".","n/a","-") ~ NA,
    str_detect(Total_cover, "<row") ~ NA,
    .default = Total_cover)
    )
```

Let's check again.

```{r}
unique(snowsurvey_fixed$Total_cover)
```

All good now, but we have values > 100. Let's convert to numeric and set these to NA.

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(Total_cover = as.numeric(Total_cover)) %>% 
  mutate(Total_cover = case_when(
    Total_cover < 0 ~ NA, # checking for negative values as well
    Total_cover > 100 ~ NA, 
    .default = Total_cover))
```

Let's check if Total_cover is now ready for infering

```{r}
unique(snowsurvey_fixed$Total_cover)

```

It's ready! Now to infer ...

```{r}
snowsurvey_fixed %>%
  filter(is.na(Snow_cover) & is.na(Water_cover) & is.na(Land_cover)) %>%
  count() # 712 rows have no cover data, so we will not be able to infer those

```

We can only infer if at least 3 of the 4 "cover" columns have valid entries (aka are not NAs).

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(
    # infer Snow_cover missing values
    Snow_cover = ifelse( # use ifelse statements to ensure enough cols have values to infer from
      is.na(Snow_cover) & !is.na(Water_cover) & !is.na(Land_cover) & !is.na(Total_cover),
      Total_cover - Water_cover - Land_cover, # infer if other 3 cols are not empty
      Snow_cover # leave value as is if conditions not met
    ),
    
    # infer Land_cover missing values 
    Land_cover = ifelse(
      is.na(Land_cover) & !is.na(Water_cover) & !is.na(Snow_cover) & !is.na(Total_cover), 
      Total_cover - Water_cover - Snow_cover,
      Land_cover
    ),
    
    # infer Water_cover missing values
      Water_cover = ifelse(
      is.na(Water_cover) & !is.na(Land_cover) & !is.na(Snow_cover) & !is.na(Total_cover), 
      Total_cover - Land_cover - Snow_cover,
      Water_cover
    ),
    
      Total_cover = ifelse(
      is.na(Total_cover) & !is.na(Land_cover) & !is.na(Snow_cover) & !is.na(Water_cover), 
      Water_cover + Land_cover + Snow_cover,
      Total_cover
  )
  )
```

Lastly, I'd like to check that we did not end up with 
1) more missing columns than before we inferred and 
2) we do not have any values > 100 in our columns of interest

```{r}
# did we create NAs? 

snowsurvey_fixed %>%
  filter(is.na(Snow_cover) & is.na(Water_cover) & is.na(Land_cover)) %>%
  count() # 712 rows have no cover data, the number did not change after inference, that is good.
```

```{r}
# do we have columns where percentage is >100? 
snowsurvey_fixed %>%
  filter(
    Snow_cover > 100 |
    Water_cover > 100 |
    Land_cover > 100 |
    Total_cover > 100)

```

We have 21 rows where Total_cover > 100! These values are not reliable. Let's set these to NA

Note: here I am making the assumption that these are data entry errors, rather than errors as a result of my inferencing. My hope is that I eliminated or reduced inference errors as much as possible with all my checks used above. 
```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Total_cover = ifelse(Total_cover > 100, NA, Total_cover))
```

What about negative numbers? 

```{r}
# do we have columns with negative numbers (<0)? 
snowsurvey_fixed %>%
  filter(
    Snow_cover < 0 |
    Water_cover < 0 |
    Land_cover < 0 |
    Total_cover < 0)

# No! all good.

```

We do not have any negative numbers either! Let's write our all_cover_fixed csv file

```{r}
# check if the folder exists
dir.create(datadir_processed, showWarnings = FALSE)

# write the file
write_csv(snowsurvey_fixed, file.path(datadir_processed, "all_cover_fixed_KaijuMorquecho.csv"))
```


